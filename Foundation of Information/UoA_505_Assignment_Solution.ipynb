{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qoNuMnVbWu6R"
   },
   "source": [
    "## Course1 : Foundation of information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hH1Zdji2Xn20"
   },
   "source": [
    "**Assignment**: Data extraction and analysis from social media platform Youtube ( 30 Marks )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tpy7c3sYXwMv"
   },
   "source": [
    "**Problem statement**\n",
    "\n",
    "Videos are a fast growing medium where people communicate, share knowledge, showcase skills etc. YouTube is one of the biggest platforms which hosts videos. The YouTube platform hosts content from many different professions/arts/ cultures across the world.\n",
    "\n",
    "People can express their opinion about the video in the form of likes, dislikes, comments which are features provided by the YouTube platform which provides the information on the sentiment about the video.\n",
    "\n",
    "The assignment involves the steps on programmatic data extraction from YouTube on which analysis can be conducted to understand various attributes related to a video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YRCnyzXNYHen"
   },
   "source": [
    "**Steps to be performed**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tTDZhZ7ZAr6"
   },
   "source": [
    "1. Connect to the Youtube API using a Python client ( 5 Marks )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8Mdbq5BZJ7C"
   },
   "source": [
    "\n",
    "\n",
    "> 1.a Create a YouTube API key (3 marks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pdA_XE4eZTA4"
   },
   "source": [
    "\n",
    "\n",
    "> 1.b Install the Google API python client  (2 marks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmyotNzTdnR1"
   },
   "source": [
    "refer to the [supporting](https://developers.google.com/youtube/v3/getting-started) link on how to create YouTube API Key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLtxyFx0XpAJ"
   },
   "source": [
    "Reference link : https://developers.google.com/youtube/v3/quickstart/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OSa8iO0RWZRq"
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade google-api-python-client\n",
    "#pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSQJfTQqZkl5"
   },
   "source": [
    "2. Search and extract the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iEs-ikIqbYFu"
   },
   "source": [
    "\n",
    "\n",
    "> 2.a Search videos related to the query string  “avatar movie”\n",
    "(For this part, choose/search one video of your choice and perform data collection steps on that specific video ) (3 marks)\n",
    "\n",
    "> Output expected : ID, Snippet with following attributes Channel ID, Video Description, Channel Title, Video Title\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ShPyoYiXSPU"
   },
   "source": [
    "Reference link:  https://developers.google.com/youtube/v3/docs/search/list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tgqRzvEfuscw"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import googleapiclient.discovery\n",
    "\n",
    "api_service_name = \"youtube\"\n",
    "api_version = 'v3'\n",
    "developer_key = \"Your API Key\"\n",
    "\n",
    "youtube = googleapiclient.discovery.build(\n",
    "    api_service_name, api_version, developerKey = developer_key)\n",
    "\n",
    "search_response = youtube.search().list(\n",
    "    q='avatar movie',\n",
    "    part='id,snippet',\n",
    "    type='video',\n",
    ").execute()\n",
    "\n",
    "video = search_response['items'][0]\n",
    "video_id = video['id']['videoId']\n",
    "snippet = video['snippet']\n",
    "channel_id = snippet['channelId']\n",
    "video_description = snippet['description']\n",
    "channel_title = snippet['channelTitle']\n",
    "video_title = snippet['title']\n",
    "\n",
    "print(f'Video ID: {video_id}')\n",
    "print(f'Snippet: {json.dumps(snippet, indent=2)}')\n",
    "print(f'Channel ID: {channel_id}')\n",
    "print(f'Video Description: {video_description}')\n",
    "print(f'Channel Title: {channel_title}')\n",
    "print(f'Video Title: {video_title}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xTAmBDZqblwN"
   },
   "source": [
    "\n",
    "> 2.b  Provide the following statistics for query string “avatar movie” of top 50 videos sorted by relevance in the US region ( 7 marks )\n",
    "\n",
    "> Output expected: video ID, title, no of views, no of likes,no of comments exported to CSV file\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4PWap3MYFdt"
   },
   "source": [
    "Reference link: https://developers.google.com/youtube/v3/docs/videos/list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x0CQ_BRsuyRp"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "# Search for the top 50 videos related to the query string \"avatar movie\" in the US region\n",
    "search_response = youtube.search().list(\n",
    "    q='avatar movie',\n",
    "    part='id, snippet',\n",
    "    type='video',\n",
    "    maxResults=50,\n",
    "    regionCode='US',\n",
    ").execute()\n",
    "\n",
    "# Get statistics for each video\n",
    "video_data_list = []\n",
    "for video in search_response['items']:\n",
    "    video_id = video['id']['videoId']\n",
    "    snippet = video['snippet']\n",
    "    video_response = youtube.videos().list(\n",
    "        part='statistics',\n",
    "        id=video_id,\n",
    "    ).execute()\n",
    "    video_statistics = video_response['items'][0]['statistics']\n",
    "    video_data = {\n",
    "        'Video ID': video_id,\n",
    "        'Title': snippet['title'],\n",
    "        'Views': video_statistics.get('viewCount', ''),\n",
    "        'Likes': video_statistics.get('likeCount', ''),\n",
    "        'Comments': video_statistics.get('commentCount', ''),\n",
    "    }\n",
    "    video_data_list.append(video_data)\n",
    "\n",
    "# Create DataFrame from video data list\n",
    "df = pd.DataFrame(video_data_list)\n",
    "\n",
    "# Write the data to a CSV file\n",
    "df.to_csv('Desktop/youtube_videos.csv', index=False)\n",
    "\n",
    "# Output the data\n",
    "print(video_data_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AoUNCXbRgQGA"
   },
   "source": [
    " 3. Analyze the exported data obtained in 2.b and carry out the following tasks (15 marks )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qe_Q2WHgT3q"
   },
   "source": [
    "\n",
    "\n",
    "> 3.a Sort the data 2.b  by top 10 comments in descending order and consider the video IDs and Titles of top 10 videos which have highest comments. (3mark)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HcG3hc45hR-a"
   },
   "outputs": [],
   "source": [
    "top_10_videos= sorted(video_data_list, key=lambda item: item['Comments'], reverse=True)[:10]\n",
    "for video in top_10_videos:\n",
    "    print(video['Video ID'] + \" \" + video['Title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4tufBbl6gj-p"
   },
   "source": [
    "\n",
    "> 3.b Use a suitable method to retrieve comments of those top 10 videos from 3.a. For doing this, write a program to loop through each video id from 3.a and pass in the part parameter set to \"snippet\", to retrieve basic details about the comments. Execute this request and print the response using the pprint() method.\n",
    " - Note: pprint() will print out the response from the API in a more human-readable format.\n",
    "- Reference link:  [link](https://developers.google.com/youtube/v3/docs )\n",
    "\n",
    "\n",
    "> **Output expected** : Use the python library “ pprint “ to print the output of the program with the following properties  etag, items, id , kind, snippet and snippet to have the text display field which represents the comment of videos.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q307uD5xhe2I"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import googleapiclient.discovery\n",
    "from pprint import pprint\n",
    "\n",
    "def get_video_comments(id):\n",
    "    request = youtube.commentThreads().list(\n",
    "        part='snippet',\n",
    "        videoId=id)\n",
    "    response = request.execute()\n",
    "    return response\n",
    "\n",
    "for video in top_10_videos:\n",
    "    pprint(get_video_comments(video['Video ID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wa-cgc1gwdbh"
   },
   "source": [
    "\n",
    "\n",
    "> 3.c Write a program to export the output of question 3.b in JSON file format and submit the file as part of the assignment (3 marks)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uRpIwASOwsg1"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "json_output = \"Desktop/json_output_comments\"\n",
    "\n",
    "with open(json_output, 'w') as json_file:\n",
    "    for video in top_10_videos:\n",
    "        json.dump(get_video_comments(video['Video ID']), json_file, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Urx4BudgxyG"
   },
   "source": [
    ">3.d Write a function to get  the likes vs views ratio of the top 10 videos obtained in 3.a with the highest comments (3 marks)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MeP1T82ihFqB"
   },
   "outputs": [],
   "source": [
    "def get_likes_views():\n",
    "    likes_views_ratios = []\n",
    "    for videos in top_10_videos:\n",
    "        likes_views_ratios.append({\n",
    "            'video_id': videos['Video ID'],\n",
    "            'ratio': int(videos['Likes']) / int(videos['Views'])})\n",
    "    return likes_views_ratios\n",
    "\n",
    "print(get_likes_views())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
